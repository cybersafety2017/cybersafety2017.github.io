---
layout: default
title: Program
permalink: /program/
order: 2
---

<h2>CyberSafety 2017: The Second International Workshop on Computational Methods for CyberSafety</h2>

<h4>Tuesday, April 4, 2017  (Workshop 12, Meeting Room 10)</h4>



<ul>
<li>9:00AM — 9:30AM: Workshop Introduction</li>

<li>9:30AM — 10:30AM: Session 1</li>
	<ul>

		<li><p>Keynote Speech: <a href="#jure-bio" data-toggle="collapse">Jure Leskovec</a> (Stanford University) <b><a href="#jure-abstract" data-toggle="collapse">Antisocial Behavior on the Web</a></b>
		<div id="jure-bio" class="collapse">
			<p>
			Bio: <a href="http://cs.stanford.edu/~jure">Jure Leskovec</a> is associate professor of Computer Science at Stanford University and chief scientist at Pinterest. Computation over massive data is at the heart of his research and has applications in computer science, social sciences, economics, marketing, and healthcare. This research has won several awards including a Lagrange Prize, Microsoft Research Faculty Fellowship, the Alfred P. Sloan Fellowship, and numerous best paper awards. Leskovec received his bachelor's degree in computer science from University of Ljubljana, Slovenia, and his PhD in in machine learning from the Carnegie Mellon University and postdoctoral training at Cornell University.
			</p>
		</div>
	
		<div id="jure-abstract" class="collapse">
			<p>
			Abstract: User contributions in the form of posts, comments, and votes are essential to the success of online communities. However, allowing user participation also invites undesirable and harmful behavior. In the talk I will discuss antisocial behavior in online discussion communities by analyzing users who were banned from these communities. We will find that such users tend to concentrate their efforts in a small number of threads, are more likely to post irrelevantly, and are more successful at garnering responses from other users. Studying the evolution of these users from the moment they join a community up to when they get banned, we find that not only do they write worse than other users over time, but they also become increasingly less tolerated by the community. Our analysis also reveals distinct groups of users with different levels of antisocial behavior that can change over time. We will use these insights to identify antisocial users early on, a task of high practical importance to community maintainers.
			</p>	
		</div>

	</p></li>
	</ul>
<li>10:30AM — 11:00AM Morning Tea</li>
<li>11:00AM — 12:30PM Session 2</li>
	<ul>
		<li><p>Invited Talk: <a href="#dali-bio" data-toggle="collapse">Dali Kaafar</a> (CSIRO Data61) <b><a href="#dali-abstract" data-toggle="collapse">Measuring, Characterising and Detecting Fake Social Activity: The Case of The Like Farms</a></b>

		<div id="dali-bio" class="collapse">
			<p>
			Bio: Prof. Dali Kaafar is a group leader of the Networks group in CSIRO Data61 and a senior principal research scientist. His main research interests include online privacy and privacy enhancing technologies, cybersecurity and networks measurement and modelling. He holds the position of visiting professor of the Chinese Academy of Science (CAS). Earlier, he held the position of research leader and principal researcher at the Mobile Networks Systems group at NICTA and senior researcher at the Privatics team at INRIA in France. He obtained an Engineering degree, an M.S from Uni of Manouba and a Ph.D. in Computer Science from INRIA Sophia Antipolice and University of Nice Sophia Antipolis. He published over 200 scientific peer-reviewed papers with several repetitive publications in IEEE INFOCOM, ACM IMC and PETS, etc. Prof. Dali Kaafar has been a member of the Privacy Enhancing Technologies Symposium board and editor of the Journal on Privacy Enhancing Technologies (PETS). In 2015, he was appointed as the editor of the IEEE Internet Computing on Small Wearables and is currently serving as the associate editor of ACM Transactions on Modeling and Performance Evaluation of Computing Systems. He is also member of several technical committees including ACM IMC 2017, CoNEXT 2017. He is the general chair of Passive Active Measurement 2017 and TPC Chair of Mobiquitous 2017.
			</p>
		</div>
	
		<div id="dali-abstract" class="collapse">
			<p>
			Abstract: Online Social Networks offer convenient ways to cheaply reach out to potentially large audiences. In particular, Facebook pages are increasingly used by businesses, brands, and organisations to connect with millions of users worldwide. As the number of likes of a page has become a de-facto measure of its popularity and profitability, alongside Facebook’s official targeted advertising platform, an underground market of services artificially inflating page likes, aka like farms, has also emerged. However, besides a few alarming media reports, there is very little work that systematically analyzes Facebook pages’ promotion methods. To fill this gap, this paper presents a honeypot-based comparative measurement study of page likes garnered via Facebook advertising and by four popular like farms. First, we analyze likes based on demographic, temporal, and social characteristics, and find that some farms seem to be operated by bots and do not really try to hide the nature of their operations, while others follow a stealthier approach, mimicking regular users’ behavior. Next, we look at fraud detection algorithms currently deployed by Facebook and show that they do not work well to detect stealthy farms which spread likes over longer timespans and like popular pages to mimic regular users. To overcome their limitations, we investigate the feasibility of timeline-based detection of like farm accounts, focusing on characterizing content generated by Facebook accounts on their timelines as an indicator of genuine versus fake social activity. We analyze a wide range of features extracted from timeline posts, which we group into two main categories: lexical and non-lexical. We find that like farm accounts tend to often re-share content, use fewer words and poorer vocabulary, and more often generate duplicate comments and likes compared to normal users.
			</p>	
		</div>
		 
		
		</p>
		<li><p><b>Measuring #GamerGate A Tale of Hate, Sexism, and Bullying</b>
Despoina Chatzakou (Aristotle University of Thessaloniki), Nicolas Kourtellis (Telefonica Research), Jeremy Blackburn (Telefonica Research), Emiliano De Cristofaro (University College London), Gianluca Stringhini (University College London), Athena Vakali (Aristotle University of Thessaloniki)</p></li>

		<li><b>Flipping 419 Cybercrime Scams: Targeting the Weak and the Vulnerable</b>
		Gibson Mba (Royal Holloway University of London),
		Jeremiah Onaolapo (University College London),
		Gianluca Stringhini (University College London),
		Lorenzo Cavallaro (Royal Holloway University of London)
 

		</li>
	</ul>



<li>12:30PM — 1:30PM  Lunch</li>

<li>1:30PM — 3:00PM Session 3</li>
	<ul>
	<li><p>Invited Talk: <a href="#min-bio" data-toggle="collapse">Min Zhang</a> (Tsinghua University) <b><a href="#min-abstract" data-toggle="collapse">Detecting Spamming Activities in Microblog, CQA and Search Queries</a></b>

	<div id="min-bio" class="collapse">
			<p>
			Bio: Dr. Min Zhang is an associate professor in the Department of Computer Science & Technology (DCST), Tsinghua University. She specializes in Web search and recommendation, user modeling and profiling. Currently she is also the vice director of State Key Lab. of Intelligent Technology and Systems (central lab), the executive director of Tsinghua University-Microsoft Research Asia Joint Research Lab on Media and Search. She also serves as associate editor for the ACM Transaction of Information Systems (TOIS), Program co-Chair of WSDM 2017 and AIRS 2016, area chairs or senior PC members at SIGIR, CIKM, and PC members at WWW, IJCAI, KDD, AAAI, ACL, etc. She has published more than 70 papers on important international journals and conferences, and has filed 12 patents.
			</p>
		</div>
	
		<div id="min-abstract" class="collapse">
			<p>
			Abstract: With the continuing popularity of the Internet, a large population of people share and access information on  Internet platforms such as microblogging, search engines, and community question and answering (CQA), which enriches our lives. Unfortunately, this widespread popularity has simultaneously resulted in incentives for fraudsters to promote their products or services illegitimately via spamming activities. Moreover, the rapid development of crowdsourcing systems creates a large-scale, potentially difficult-to-detect workforce to manipulate malicious activities on the Internet. In this talk, I will introduce our recent progress on investigating the newly observed spamming activities on different types of mainstream Internet platforms and developing novel frameworks to discern them. There are three major research results: 1) detecting of crowdturfing following activities in microblog environments; 2) identifying promotion campaigns in Query Auto Completion; and 3) detecting collusive spamming activities in Community Question Answering.
			</p>	
		</div>
</p></li>




<li><b>Scamming the Scammers: Towards Automatic Detection of Persuasion in Advance Fee Frauds</b> 
Matthew Edwards (Lancaster University),
Claudia Peersman (Lancaster University),
Await Rashid (Lancaster University)</li>

<li><b>Ethical and Social Challenges with developing Automated Methods to Detect and Warn potential victims of Mass-marketing Fraud (MMF)</b> 
M. T. Whitty (University of Warwick),
M. Edwards (Lancaster University),
M. Levi (Cardiff University),
C. Peersman (Lancaster University),
A. Rashid (Lancaster University),
A. Sasse (University College London) ,
T. Sorell (University of Warwick),
G. Stringhini (University College London)</li>
</ul>

<li>3:00PM — 3:30PM Afternoon Tea</li>

<li>3:30PM — 4:30PM Session 4</li>
<ul><li>Panel Discussion / Open Forum</li></ul>

<li>4:30PM — 5:00PM Closing Remarks</li>
</ul>